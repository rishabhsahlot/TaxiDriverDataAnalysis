{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\risha\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\risha\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\risha\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\risha\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_taxi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c09e914e5bd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;31m# First and foremost we clean the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;31m# 1. Remove All values with trip distance less than or equal to 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m \u001b[0mdf_taxi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_taxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_taxi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_taxi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trip_distance'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;31m# 2. Remove All values with total amount less than 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[0mdf_taxi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_taxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_taxi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_taxi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total_amount'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_taxi' is not defined"
     ]
    }
   ],
   "source": [
    "# Authors - Karanjit Singh, Rishabh Manish Sahlot, Tejas Patel\n",
    "from myutils import hourToLabelEncoder\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "# Estabilishing a connection with an already existing database named taxi_data\n",
    "db = client['taxi_data']\n",
    "# Selecting the collection/table yellowtaxi_data\n",
    "coll = db['yellowtaxi_data']\n",
    "coll.drop()\n",
    "\n",
    "# Initializing the Folder paths\n",
    "raw_data_path = 'Raw_Data/'\n",
    "processed_data_path = 'Processed_Data/'\n",
    "links_data_path = 'Data_Links/'\n",
    "# Reading the df_nypd data\n",
    "df_nypd = pd.read_csv(raw_data_path+'nypd_data.csv')\n",
    "# Finding the year and month of crime for the nypd data\n",
    "df_nypd['year of crime'] = list(map(lambda x: str(x.split('/')[2]), df_nypd['ARREST_DATE'].values))\n",
    "df_nypd['month of crime'] = list(map(lambda x: str(x.split('/')[0]), df_nypd['ARREST_DATE'].values))\n",
    "# Aggregating the number of arrests for each precinct\n",
    "crime_counts = df_nypd.groupby('ARREST_PRECINCT').agg(['count'])['ARREST_KEY']\n",
    "# Saving the new df_nypd file in the porcessed data as well as removing it from the memory\n",
    "# Since it will not be used the preprocessing henceforth.\n",
    "#df_nypd.to_csv(processed_data_path +'nypd_data.csv')\n",
    "del df_nypd\n",
    "# Reading the precinct lookup table\n",
    "df_taxi_with_precint = pd.read_csv(links_data_path+'taxi_with_precint.csv')\n",
    "# Correcting the pipe separated values to array elements in the 'Corresponding_Taxi_Zones' column\n",
    "df_taxi_with_precint['Corresponding_Taxi_Zones'] = list( map(lambda x: list(map(int,x.split('|'))),df_taxi_with_precint['Corresponding_Taxi_Zones'].values))\n",
    "# merging the counts of arrest for each precint and the Corresponding Taxi Zones for the Precint\n",
    "crime_counts = crime_counts.merge(df_taxi_with_precint, left_on='ARREST_PRECINCT', right_on='NYPD Precinct')\n",
    "# Saving (in the processed Folder) and deleting(from the program cache) the precinct lookup\n",
    "# since it's use has been over.\n",
    "#df_taxi_with_precint.to_csv(processed_data_path +'taxi_with_precint.csv')\n",
    "del df_taxi_with_precint\n",
    "# Assigning crime rate labels for hardcoded(using visualization) values of arrest counts\n",
    "crime_counts['CrimeRate'] = 1\n",
    "crime_counts['CrimeRate'][crime_counts['count'] < 45000] = 'Low Crime'\n",
    "crime_counts['CrimeRate'][(crime_counts['count'] >= 45000) & (crime_counts['count'] < 90000)] = 'Medium Crime'\n",
    "crime_counts['CrimeRate'][crime_counts['count'] >= 90000] = 'High Crime'\n",
    "# Flattening / unwinding the crime counts to get each taxi zone\n",
    "crime_counts = crime_counts.explode('Corresponding_Taxi_Zones')\n",
    "\n",
    "## Moving on to University Data\n",
    "# Reading the university data\n",
    "df_uni = pd.read_csv(raw_data_path+'cuny_locations.csv')\n",
    "# The above data is clean and should be saved and deleted from memory since it has no later significance\n",
    "df_uni.to_csv(processed_data_path +'cuny_location.csv')\n",
    "del df_uni\n",
    "# Reading Univeristy Lookup Table as well as saving it to it's corresponding Location\n",
    "df_uni_lookup = pd.read_csv(links_data_path+'taxi_with_cuny.csv')\n",
    "#df_uni_lookup.to_csv(processed_data_path+'taxi_with_cuny.csv')\n",
    "\n",
    "#Moving on to the taxi Data\n",
    "# Reading the taxi zone lookup data\n",
    "df_taxi_zone_lookup = pd.read_csv(links_data_path+'taxi_zone_lookup.csv')\n",
    "# Since it contains all the location ID's in the taxi data, we can do the merging\n",
    "# operation to this one- this saves a lot of time and program memory\n",
    "df_taxi_zone_lookup = pd.merge(df_taxi_zone_lookup, crime_counts[['Corresponding_Taxi_Zones','CrimeRate']], left_on='LocationID', right_on='Corresponding_Taxi_Zones', how='left')\n",
    "df_taxi_zone_lookup = pd.merge(df_taxi_zone_lookup, df_uni_lookup, left_on='LocationID', right_on='Location ID', how='left')\n",
    "# Freeing space of the non-essential merged items\n",
    "del crime_counts\n",
    "del df_uni_lookup\n",
    "#Now using the College ID data obtained from we add the HasSchool feature\n",
    "df_taxi_zone_lookup['HasSchool'] = 'false'\n",
    "df_taxi_zone_lookup['HasSchool'][df_taxi_zone_lookup['College ID'].notna()] = 'true'\n",
    "# We then drop of waste columns\n",
    "del df_taxi_zone_lookup['Location ID']\n",
    "del df_taxi_zone_lookup['Corresponding_Taxi_Zones']\n",
    "del df_taxi_zone_lookup['College ID']\n",
    "del df_taxi_zone_lookup['Zone']\n",
    "del df_taxi_zone_lookup['service_zone']\n",
    "\n",
    "# Finally we read the taxi trip data\n",
    "df_taxi = pd.read_csv(raw_data_path+'yellowtaxi_data.csv')\n",
    "# First and foremost we clean the data\n",
    "# 1. Remove All values with trip distance less than or equal to 0\n",
    "df_taxi = df_taxi.drop(df_taxi[df_taxi['trip_distance'] <= 0].index)\n",
    "# 2. Remove All values with total amount less than 0\n",
    "df_taxi = df_taxi.drop(df_taxi[df_taxi['total_amount'] <= 0].index)\n",
    "# 3.\n",
    "df_taxi = df_taxi.drop(df_taxi[df_taxi['extra'] < 0].index)\n",
    "#4.\n",
    "df_taxi = df_taxi.drop(df_taxi[df_taxi['PULocationID'] > 263].index)\n",
    "#5.\n",
    "df_taxi = df_taxi.drop(df_taxi[df_taxi['DOLocationID'] > 263].index)\n",
    "# Fix the date time columns\n",
    "df_taxi['tpep_pickup_datetime'] = list(map(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'), df_taxi['tpep_pickup_datetime'].values))\n",
    "df_taxi['tpep_dropoff_datetime'] =list(map(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'), df_taxi['tpep_dropoff_datetime'].values))\n",
    "# Calculate trip duration in hours\n",
    "df_taxi['Trip duration'] = list(map(lambda x: x.item()/(3600*(10**9)), (df_taxi['tpep_dropoff_datetime']-df_taxi['tpep_pickup_datetime']).values))\n",
    "# Incidently I found that trip duration becomes negative in some cases i.e. pickup happening after drop off, we dont try to analyze these values and simply eliminate them\n",
    "df_taxi = df_taxi.drop(df_taxi[df_taxi['Trip duration'] <= 0].index)\n",
    "\n",
    "# Calculating average speed during the trip\n",
    "df_taxi['Speed'] = df_taxi['trip_distance']/df_taxi['Trip duration']\n",
    "# Thresholding for speed to predict traffic such lower speed of vehicles implies higher traffic\n",
    "df_taxi['Traffic'] = 0\n",
    "df_taxi['Traffic'][df_taxi['Speed']<=10] = 'High Traffic'\n",
    "df_taxi['Traffic'][(df_taxi['Speed']>10) & (df_taxi['Speed']<=25)] = 'Medium Traffic'\n",
    "df_taxi['Traffic'][df_taxi['Speed']>25] = 'Low Traffic'\n",
    "# Calculating Hour the the dat HoD for the dropoff (DOHoD) & pickup values (PUHoD)\n",
    "df_taxi['DOHoD'] = df_taxi['tpep_dropoff_datetime'].astype('datetime64[ns]').dt.hour\n",
    "df_taxi['PUHoD'] = df_taxi['tpep_pickup_datetime'].astype('datetime64[ns]').dt.hour\n",
    "# Calculating the respective Time Codes using these values\n",
    "df_taxi['DOTimeCode'] = list(map(lambda x: hourToLabelEncoder(x), df_taxi['DOHoD'].values))\n",
    "df_taxi['PUTimeCode'] = list(map(lambda x: hourToLabelEncoder(x), df_taxi['PUHoD'].values))\n",
    "# Finally Merging All the Data From the combined taxi zone lookup data\n",
    "df_taxi = pd.merge(df_taxi, df_taxi_zone_lookup, left_on='PULocationID', right_on='LocationID',how='left')\n",
    "#Getting columns of the comibined values\n",
    "exterior_columns = df_taxi_zone_lookup.columns\n",
    "# Changing names in dt_taxi to indicate they are for pickup location\n",
    "for cols in exterior_columns:\n",
    "    df_taxi.rename(columns={cols: 'PU'+cols}, inplace=True)\n",
    "# Repeating the same with DO locations\n",
    "df_taxi = pd.merge(df_taxi, df_taxi_zone_lookup, left_on='DOLocationID', right_on='LocationID',how='left')\n",
    "#Storing & Deleting the combined values\n",
    "df_taxi_zone_lookup.to_csv(processed_data_path+'taxi_zone_lookup.csv')\n",
    "del df_taxi_zone_lookup\n",
    "# Changing names in dt_taxi to indicate they are for pickup location\n",
    "for cols in exterior_columns:\n",
    "    df_taxi.rename(columns={cols: 'DO'+cols}, inplace=True)\n",
    "\n",
    "# Finally storing the taxi data at it's require position\n",
    "#df_taxi.to_csv(processed_data_path+'yellowtaxi_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
